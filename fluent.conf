#This pulls the data from the host docker directory when the JSON file docker logging driver is used
<source>
  @type tail
  path /var/lib/docker/containers/*/*-json.log
  pos_file fluentd-docker.pos
  time_format %Y-%m-%dT%H:%M:%S
  tag ecs.*
  format json
#  read_from_head true
</source>

#This makes use of the ECS Metadata plugin to enrich records with ECS metadata
<filter **>
  type ecs_metadata
</filter>

#This match updates the tag to include all ECS metadata for routing 
<match ecs.**>
  type record_reformer
  tag ${record['ecs']}
</match>

#This copies the FluentD field log over to message for increased usability within the Kibana Discover page
<match *.*>
  @type record_reformer
  renew_record false
  enable_ruby false
  tag logcopy
  <record>
    message ${log}
  </record>
</match>

#This is for sending to a file for testing prior to sending to Logz.io
<match **>
      type logzio_buffered
      endpoint_url "#{ENV['LOGZ_IO_URL_1']}"
      output_include_time true
      output_include_tags true
      buffer_type    file
      buffer_path    /tmp/logsz_buffer
      flush_interval 1s
      buffer_chunk_limit 1m   # Logz.io has bulk limit of 10M. We recommend set this to 1M, to avoid oversized bulks
</match>



#This is for sending to a file for testing prior to sending to Logz.io
# <match *ubuntusampleapp-1*>
#       type logzio_buffered
#       endpoint_url "#{ENV['LOGZ_IO_URL_1']}"
#       output_include_time true
#       output_include_tags true
#       buffer_type    file
#       buffer_path    /tmp/logsz_buffer
#       flush_interval 1s
#       buffer_chunk_limit 1m   # Logz.io has bulk limit of 10M. We recommend set this to 1M, to avoid oversized bulks
# </match>

# #This is for sending to a file for testing prior to sending to Logz.io
# <match *ubuntusampleapp-2*>
#       type logzio_buffered
#       endpoint_url "#{ENV['LOGZ_IO_URL_2']}"
#       output_include_time true
#       output_include_tags true
#       buffer_type    file
#       buffer_path    /tmp/logsz_buffer
#       flush_interval 1s
#       buffer_chunk_limit 1m   # Logz.io has bulk limit of 10M. We recommend set this to 1M, to avoid oversized bulks
# </match>


#This is for sending to a file for testing prior to sending to Logz.io
#<match *ubuntusampleapp-1*>
#  @type file
#  path /tmp/test0
#  time_slice_format %Y%m%d
#  time_slice_wait 10m
#  time_format %Y%m%dT%H%M%S%z
#  utc
#</match>

#This is for sending to a file for testing prior to sending to Logz.io
#<match *ubuntusampleapp-2*>
#  @type file
#  path /tmp/test1
#  time_slice_format %Y%m%d
#  time_slice_wait 10m
#  time_format %Y%m%dT%H%M%S%z
#  utc
#</match>

#This is for sending to a file for testing prior to sending to Logz.io
#<match **>
#  @type file
#  path /tmp/testcatchall
#  time_slice_format %Y%m%d
#  time_slice_wait 10m
#  time_format %Y%m%dT%H%M%S%z
#  utc
#</match>